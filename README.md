# Fake News Detection with NLP

![GIF Description](README_images/readme.gif)

This repository contains the code and resources for detecting fake news using Natural Language Processing (NLP) and pre-trained transformer language models. The project was developed by Anna Punzengruber, Martin Stasek, Carlos Eduardo Tichy, and Anna Till.

## Overview

Fake news has a significant negative impact on areas such as politics, health, and economics. It spreads rapidly online through social media and undermines trust in institutions, making it difficult for consumers to discern credible information. Manual fact-checking is slow, expensive, and not scalable. Our goal is to leverage transformer-based NLP models—such as BERT, DistilBERT, RoBERTa, (and DeBERTa)—to automatically detect fake news from textual statements and associated metadata.

## Datasets

This project utilizes three distinct datasets for fake news detection:

- **[ISOT Fake News Dataset](https://www.kaggle.com/datasets/csmalarkodi/isot-fake-news-dataset/):** Contains full-length news articles, with roughly 21.4k true and 23.5k fake news samples.
- **[LIAR Dataset](https://www.kaggle.com/datasets/doanquanvietnamca/liar-dataset):** Comprises manually labeled short statements, originally sourced from Politifact, with separate train, test, and validation splits.
- **[FEVER Dataset](https://fever.ai/dataset/fever.html):** Generated by modifying Wikipedia sentences to create claims for evaluation.

Each dataset is housed in its own subfolder within the repository, and you will find dedicated code and instructions (in a README) tailored to that dataset.

## Requirements

- **Python Version:** Python 3.12 is used for all datasets.
- **Package Dependencies:** Note that package requirements may vary between datasets. Please refer to the individual README/requirement files in each dataset's subfolder for specific dependency instructions.