{
  "best_metric": 0.7286352698521829,
  "best_model_checkpoint": "./results/BERT\\checkpoint-58180",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 72725,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.034376074252320386,
      "grad_norm": 6.716926574707031,
      "learning_rate": 1.986249570299072e-05,
      "loss": 1.0358,
      "step": 500
    },
    {
      "epoch": 0.06875214850464077,
      "grad_norm": 3.955193042755127,
      "learning_rate": 1.972499140598144e-05,
      "loss": 1.001,
      "step": 1000
    },
    {
      "epoch": 0.10312822275696115,
      "grad_norm": 5.565029144287109,
      "learning_rate": 1.9587487108972157e-05,
      "loss": 1.0066,
      "step": 1500
    },
    {
      "epoch": 0.13750429700928155,
      "grad_norm": 5.134533882141113,
      "learning_rate": 1.9449982811962875e-05,
      "loss": 0.9327,
      "step": 2000
    },
    {
      "epoch": 0.17188037126160194,
      "grad_norm": 22.12596321105957,
      "learning_rate": 1.9312478514953594e-05,
      "loss": 0.8785,
      "step": 2500
    },
    {
      "epoch": 0.2062564455139223,
      "grad_norm": 12.3390531539917,
      "learning_rate": 1.9174974217944312e-05,
      "loss": 0.8473,
      "step": 3000
    },
    {
      "epoch": 0.2406325197662427,
      "grad_norm": 7.342688083648682,
      "learning_rate": 1.903746992093503e-05,
      "loss": 0.8018,
      "step": 3500
    },
    {
      "epoch": 0.2750085940185631,
      "grad_norm": 8.59630298614502,
      "learning_rate": 1.889996562392575e-05,
      "loss": 0.7932,
      "step": 4000
    },
    {
      "epoch": 0.30938466827088346,
      "grad_norm": 6.38711404800415,
      "learning_rate": 1.8762461326916468e-05,
      "loss": 0.7712,
      "step": 4500
    },
    {
      "epoch": 0.3437607425232039,
      "grad_norm": 6.986225128173828,
      "learning_rate": 1.8624957029907186e-05,
      "loss": 0.777,
      "step": 5000
    },
    {
      "epoch": 0.37813681677552424,
      "grad_norm": 12.018972396850586,
      "learning_rate": 1.8487452732897905e-05,
      "loss": 0.7607,
      "step": 5500
    },
    {
      "epoch": 0.4125128910278446,
      "grad_norm": 9.312942504882812,
      "learning_rate": 1.8349948435888623e-05,
      "loss": 0.7672,
      "step": 6000
    },
    {
      "epoch": 0.44688896528016503,
      "grad_norm": 6.857250213623047,
      "learning_rate": 1.821244413887934e-05,
      "loss": 0.7591,
      "step": 6500
    },
    {
      "epoch": 0.4812650395324854,
      "grad_norm": 7.209392547607422,
      "learning_rate": 1.807493984187006e-05,
      "loss": 0.7258,
      "step": 7000
    },
    {
      "epoch": 0.5156411137848058,
      "grad_norm": 5.115551471710205,
      "learning_rate": 1.793743554486078e-05,
      "loss": 0.7288,
      "step": 7500
    },
    {
      "epoch": 0.5500171880371262,
      "grad_norm": 7.229748249053955,
      "learning_rate": 1.7799931247851497e-05,
      "loss": 0.7493,
      "step": 8000
    },
    {
      "epoch": 0.5843932622894465,
      "grad_norm": 10.635336875915527,
      "learning_rate": 1.7662426950842215e-05,
      "loss": 0.7421,
      "step": 8500
    },
    {
      "epoch": 0.6187693365417669,
      "grad_norm": 15.656001091003418,
      "learning_rate": 1.7524922653832934e-05,
      "loss": 0.7376,
      "step": 9000
    },
    {
      "epoch": 0.6531454107940873,
      "grad_norm": 8.284933090209961,
      "learning_rate": 1.7387418356823652e-05,
      "loss": 0.7571,
      "step": 9500
    },
    {
      "epoch": 0.6875214850464078,
      "grad_norm": 9.402363777160645,
      "learning_rate": 1.724991405981437e-05,
      "loss": 0.7158,
      "step": 10000
    },
    {
      "epoch": 0.7218975592987281,
      "grad_norm": 8.487504005432129,
      "learning_rate": 1.711240976280509e-05,
      "loss": 0.7343,
      "step": 10500
    },
    {
      "epoch": 0.7562736335510485,
      "grad_norm": 11.981077194213867,
      "learning_rate": 1.6974905465795807e-05,
      "loss": 0.7246,
      "step": 11000
    },
    {
      "epoch": 0.7906497078033689,
      "grad_norm": 9.31552505493164,
      "learning_rate": 1.6837401168786526e-05,
      "loss": 0.7278,
      "step": 11500
    },
    {
      "epoch": 0.8250257820556892,
      "grad_norm": 7.598433494567871,
      "learning_rate": 1.6699896871777244e-05,
      "loss": 0.74,
      "step": 12000
    },
    {
      "epoch": 0.8594018563080096,
      "grad_norm": 12.50836181640625,
      "learning_rate": 1.6562392574767963e-05,
      "loss": 0.7071,
      "step": 12500
    },
    {
      "epoch": 0.8937779305603301,
      "grad_norm": 8.784929275512695,
      "learning_rate": 1.642488827775868e-05,
      "loss": 0.7107,
      "step": 13000
    },
    {
      "epoch": 0.9281540048126504,
      "grad_norm": 6.197542667388916,
      "learning_rate": 1.62873839807494e-05,
      "loss": 0.728,
      "step": 13500
    },
    {
      "epoch": 0.9625300790649708,
      "grad_norm": 6.036182403564453,
      "learning_rate": 1.6149879683740118e-05,
      "loss": 0.7102,
      "step": 14000
    },
    {
      "epoch": 0.9969061533172912,
      "grad_norm": 5.161589622497559,
      "learning_rate": 1.6012375386730837e-05,
      "loss": 0.7149,
      "step": 14500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7134754211069096,
      "eval_f1": 0.6923169246531389,
      "eval_loss": 0.712267279624939,
      "eval_precision": 0.7108194422739738,
      "eval_recall": 0.7134754211069096,
      "eval_runtime": 223.1328,
      "eval_samples_per_second": 130.371,
      "eval_steps_per_second": 16.3,
      "step": 14545
    },
    {
      "epoch": 1.0312822275696116,
      "grad_norm": 19.153841018676758,
      "learning_rate": 1.5874871089721555e-05,
      "loss": 0.6266,
      "step": 15000
    },
    {
      "epoch": 1.0656583018219319,
      "grad_norm": 4.325503349304199,
      "learning_rate": 1.5737366792712274e-05,
      "loss": 0.6367,
      "step": 15500
    },
    {
      "epoch": 1.1000343760742524,
      "grad_norm": 7.257952690124512,
      "learning_rate": 1.5599862495702992e-05,
      "loss": 0.6298,
      "step": 16000
    },
    {
      "epoch": 1.1344104503265726,
      "grad_norm": 15.629335403442383,
      "learning_rate": 1.546235819869371e-05,
      "loss": 0.6197,
      "step": 16500
    },
    {
      "epoch": 1.168786524578893,
      "grad_norm": 22.254581451416016,
      "learning_rate": 1.532485390168443e-05,
      "loss": 0.6303,
      "step": 17000
    },
    {
      "epoch": 1.2031625988312136,
      "grad_norm": 12.377492904663086,
      "learning_rate": 1.5187349604675147e-05,
      "loss": 0.6301,
      "step": 17500
    },
    {
      "epoch": 1.2375386730835338,
      "grad_norm": 17.517919540405273,
      "learning_rate": 1.5049845307665867e-05,
      "loss": 0.6183,
      "step": 18000
    },
    {
      "epoch": 1.2719147473358543,
      "grad_norm": 5.9277801513671875,
      "learning_rate": 1.4912341010656584e-05,
      "loss": 0.6502,
      "step": 18500
    },
    {
      "epoch": 1.3062908215881746,
      "grad_norm": 7.85957145690918,
      "learning_rate": 1.4774836713647303e-05,
      "loss": 0.6107,
      "step": 19000
    },
    {
      "epoch": 1.340666895840495,
      "grad_norm": 18.657743453979492,
      "learning_rate": 1.4637332416638021e-05,
      "loss": 0.6515,
      "step": 19500
    },
    {
      "epoch": 1.3750429700928155,
      "grad_norm": 7.289359092712402,
      "learning_rate": 1.4499828119628741e-05,
      "loss": 0.6208,
      "step": 20000
    },
    {
      "epoch": 1.4094190443451358,
      "grad_norm": 6.286043643951416,
      "learning_rate": 1.4362323822619458e-05,
      "loss": 0.6387,
      "step": 20500
    },
    {
      "epoch": 1.4437951185974562,
      "grad_norm": 24.47428321838379,
      "learning_rate": 1.4224819525610176e-05,
      "loss": 0.6127,
      "step": 21000
    },
    {
      "epoch": 1.4781711928497765,
      "grad_norm": 7.881985187530518,
      "learning_rate": 1.4087315228600895e-05,
      "loss": 0.632,
      "step": 21500
    },
    {
      "epoch": 1.512547267102097,
      "grad_norm": 7.44713020324707,
      "learning_rate": 1.3949810931591613e-05,
      "loss": 0.6152,
      "step": 22000
    },
    {
      "epoch": 1.5469233413544172,
      "grad_norm": 14.446290969848633,
      "learning_rate": 1.381230663458233e-05,
      "loss": 0.6155,
      "step": 22500
    },
    {
      "epoch": 1.5812994156067377,
      "grad_norm": 10.430439949035645,
      "learning_rate": 1.367480233757305e-05,
      "loss": 0.6413,
      "step": 23000
    },
    {
      "epoch": 1.6156754898590582,
      "grad_norm": 7.244133949279785,
      "learning_rate": 1.3537298040563769e-05,
      "loss": 0.6303,
      "step": 23500
    },
    {
      "epoch": 1.6500515641113784,
      "grad_norm": 6.176677227020264,
      "learning_rate": 1.3399793743554487e-05,
      "loss": 0.6272,
      "step": 24000
    },
    {
      "epoch": 1.684427638363699,
      "grad_norm": 5.93399715423584,
      "learning_rate": 1.3262289446545204e-05,
      "loss": 0.6389,
      "step": 24500
    },
    {
      "epoch": 1.7188037126160194,
      "grad_norm": 10.051980972290039,
      "learning_rate": 1.3124785149535924e-05,
      "loss": 0.6409,
      "step": 25000
    },
    {
      "epoch": 1.7531797868683396,
      "grad_norm": 12.901071548461914,
      "learning_rate": 1.2987280852526642e-05,
      "loss": 0.6155,
      "step": 25500
    },
    {
      "epoch": 1.78755586112066,
      "grad_norm": 11.651710510253906,
      "learning_rate": 1.2849776555517361e-05,
      "loss": 0.6444,
      "step": 26000
    },
    {
      "epoch": 1.8219319353729804,
      "grad_norm": 19.174549102783203,
      "learning_rate": 1.2712272258508081e-05,
      "loss": 0.6069,
      "step": 26500
    },
    {
      "epoch": 1.8563080096253008,
      "grad_norm": 8.611261367797852,
      "learning_rate": 1.2574767961498798e-05,
      "loss": 0.6139,
      "step": 27000
    },
    {
      "epoch": 1.890684083877621,
      "grad_norm": 11.21539306640625,
      "learning_rate": 1.2437263664489516e-05,
      "loss": 0.6144,
      "step": 27500
    },
    {
      "epoch": 1.9250601581299416,
      "grad_norm": 7.609725475311279,
      "learning_rate": 1.2299759367480235e-05,
      "loss": 0.6202,
      "step": 28000
    },
    {
      "epoch": 1.959436232382262,
      "grad_norm": 13.300559997558594,
      "learning_rate": 1.2162255070470955e-05,
      "loss": 0.6263,
      "step": 28500
    },
    {
      "epoch": 1.9938123066345823,
      "grad_norm": 14.154826164245605,
      "learning_rate": 1.2024750773461672e-05,
      "loss": 0.6402,
      "step": 29000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.7244070127191474,
      "eval_f1": 0.7106493954582759,
      "eval_loss": 0.6939932703971863,
      "eval_precision": 0.7202417494561286,
      "eval_recall": 0.7244070127191474,
      "eval_runtime": 221.0908,
      "eval_samples_per_second": 131.575,
      "eval_steps_per_second": 16.45,
      "step": 29090
    },
    {
      "epoch": 2.0281883808869026,
      "grad_norm": 24.78409767150879,
      "learning_rate": 1.188724647645239e-05,
      "loss": 0.521,
      "step": 29500
    },
    {
      "epoch": 2.0625644551392233,
      "grad_norm": 13.156150817871094,
      "learning_rate": 1.1749742179443108e-05,
      "loss": 0.5265,
      "step": 30000
    },
    {
      "epoch": 2.0969405293915435,
      "grad_norm": 19.256513595581055,
      "learning_rate": 1.1612237882433827e-05,
      "loss": 0.5139,
      "step": 30500
    },
    {
      "epoch": 2.1313166036438638,
      "grad_norm": 6.107081890106201,
      "learning_rate": 1.1474733585424544e-05,
      "loss": 0.4973,
      "step": 31000
    },
    {
      "epoch": 2.1656926778961845,
      "grad_norm": 4.252411365509033,
      "learning_rate": 1.1337229288415264e-05,
      "loss": 0.5136,
      "step": 31500
    },
    {
      "epoch": 2.2000687521485047,
      "grad_norm": 9.913244247436523,
      "learning_rate": 1.1199724991405982e-05,
      "loss": 0.5057,
      "step": 32000
    },
    {
      "epoch": 2.234444826400825,
      "grad_norm": 15.54327392578125,
      "learning_rate": 1.10622206943967e-05,
      "loss": 0.5245,
      "step": 32500
    },
    {
      "epoch": 2.2688209006531452,
      "grad_norm": 8.82065486907959,
      "learning_rate": 1.0924716397387417e-05,
      "loss": 0.4998,
      "step": 33000
    },
    {
      "epoch": 2.303196974905466,
      "grad_norm": 7.988988399505615,
      "learning_rate": 1.0787212100378138e-05,
      "loss": 0.5212,
      "step": 33500
    },
    {
      "epoch": 2.337573049157786,
      "grad_norm": 2.7917914390563965,
      "learning_rate": 1.0649707803368856e-05,
      "loss": 0.5061,
      "step": 34000
    },
    {
      "epoch": 2.3719491234101064,
      "grad_norm": 17.696128845214844,
      "learning_rate": 1.0512203506359575e-05,
      "loss": 0.5065,
      "step": 34500
    },
    {
      "epoch": 2.406325197662427,
      "grad_norm": 25.201858520507812,
      "learning_rate": 1.0374699209350295e-05,
      "loss": 0.5202,
      "step": 35000
    },
    {
      "epoch": 2.4407012719147474,
      "grad_norm": 15.131303787231445,
      "learning_rate": 1.0237194912341011e-05,
      "loss": 0.5194,
      "step": 35500
    },
    {
      "epoch": 2.4750773461670676,
      "grad_norm": 31.719457626342773,
      "learning_rate": 1.009969061533173e-05,
      "loss": 0.4984,
      "step": 36000
    },
    {
      "epoch": 2.509453420419388,
      "grad_norm": 13.601419448852539,
      "learning_rate": 9.962186318322448e-06,
      "loss": 0.5267,
      "step": 36500
    },
    {
      "epoch": 2.5438294946717086,
      "grad_norm": 7.048270225524902,
      "learning_rate": 9.824682021313167e-06,
      "loss": 0.5166,
      "step": 37000
    },
    {
      "epoch": 2.578205568924029,
      "grad_norm": 16.185571670532227,
      "learning_rate": 9.687177724303885e-06,
      "loss": 0.5246,
      "step": 37500
    },
    {
      "epoch": 2.612581643176349,
      "grad_norm": 28.36086082458496,
      "learning_rate": 9.549673427294604e-06,
      "loss": 0.5112,
      "step": 38000
    },
    {
      "epoch": 2.64695771742867,
      "grad_norm": 8.331846237182617,
      "learning_rate": 9.412169130285322e-06,
      "loss": 0.534,
      "step": 38500
    },
    {
      "epoch": 2.68133379168099,
      "grad_norm": 28.283761978149414,
      "learning_rate": 9.27466483327604e-06,
      "loss": 0.5093,
      "step": 39000
    },
    {
      "epoch": 2.7157098659333103,
      "grad_norm": 9.442763328552246,
      "learning_rate": 9.137160536266759e-06,
      "loss": 0.5226,
      "step": 39500
    },
    {
      "epoch": 2.750085940185631,
      "grad_norm": 15.027939796447754,
      "learning_rate": 8.999656239257477e-06,
      "loss": 0.5243,
      "step": 40000
    },
    {
      "epoch": 2.7844620144379513,
      "grad_norm": 19.337003707885742,
      "learning_rate": 8.862151942248196e-06,
      "loss": 0.5217,
      "step": 40500
    },
    {
      "epoch": 2.8188380886902715,
      "grad_norm": 7.054086685180664,
      "learning_rate": 8.724647645238914e-06,
      "loss": 0.5079,
      "step": 41000
    },
    {
      "epoch": 2.8532141629425922,
      "grad_norm": 25.773786544799805,
      "learning_rate": 8.587143348229633e-06,
      "loss": 0.5195,
      "step": 41500
    },
    {
      "epoch": 2.8875902371949125,
      "grad_norm": 3.587148666381836,
      "learning_rate": 8.449639051220351e-06,
      "loss": 0.5354,
      "step": 42000
    },
    {
      "epoch": 2.9219663114472327,
      "grad_norm": 8.426344871520996,
      "learning_rate": 8.31213475421107e-06,
      "loss": 0.4923,
      "step": 42500
    },
    {
      "epoch": 2.956342385699553,
      "grad_norm": 12.403528213500977,
      "learning_rate": 8.174630457201788e-06,
      "loss": 0.5108,
      "step": 43000
    },
    {
      "epoch": 2.9907184599518732,
      "grad_norm": 15.141791343688965,
      "learning_rate": 8.037126160192507e-06,
      "loss": 0.5415,
      "step": 43500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.7258508078377449,
      "eval_f1": 0.7150497822254791,
      "eval_loss": 0.8002759218215942,
      "eval_precision": 0.7175797162795315,
      "eval_recall": 0.7258508078377449,
      "eval_runtime": 221.1199,
      "eval_samples_per_second": 131.558,
      "eval_steps_per_second": 16.448,
      "step": 43635
    },
    {
      "epoch": 3.025094534204194,
      "grad_norm": 36.87784957885742,
      "learning_rate": 7.899621863183225e-06,
      "loss": 0.4075,
      "step": 44000
    },
    {
      "epoch": 3.059470608456514,
      "grad_norm": 60.31679153442383,
      "learning_rate": 7.762117566173943e-06,
      "loss": 0.4226,
      "step": 44500
    },
    {
      "epoch": 3.0938466827088345,
      "grad_norm": 3.0694072246551514,
      "learning_rate": 7.624613269164663e-06,
      "loss": 0.4212,
      "step": 45000
    },
    {
      "epoch": 3.128222756961155,
      "grad_norm": 31.719280242919922,
      "learning_rate": 7.48710897215538e-06,
      "loss": 0.4419,
      "step": 45500
    },
    {
      "epoch": 3.1625988312134754,
      "grad_norm": 18.767457962036133,
      "learning_rate": 7.349604675146099e-06,
      "loss": 0.4232,
      "step": 46000
    },
    {
      "epoch": 3.1969749054657957,
      "grad_norm": 14.031574249267578,
      "learning_rate": 7.212100378136817e-06,
      "loss": 0.4262,
      "step": 46500
    },
    {
      "epoch": 3.2313509797181164,
      "grad_norm": 8.571406364440918,
      "learning_rate": 7.074596081127536e-06,
      "loss": 0.4114,
      "step": 47000
    },
    {
      "epoch": 3.2657270539704366,
      "grad_norm": 8.508736610412598,
      "learning_rate": 6.937091784118254e-06,
      "loss": 0.4181,
      "step": 47500
    },
    {
      "epoch": 3.300103128222757,
      "grad_norm": 9.639202117919922,
      "learning_rate": 6.799587487108973e-06,
      "loss": 0.4314,
      "step": 48000
    },
    {
      "epoch": 3.3344792024750776,
      "grad_norm": 31.105121612548828,
      "learning_rate": 6.662083190099691e-06,
      "loss": 0.4025,
      "step": 48500
    },
    {
      "epoch": 3.368855276727398,
      "grad_norm": 13.124011039733887,
      "learning_rate": 6.5245788930904095e-06,
      "loss": 0.436,
      "step": 49000
    },
    {
      "epoch": 3.403231350979718,
      "grad_norm": 7.96096134185791,
      "learning_rate": 6.387074596081128e-06,
      "loss": 0.4091,
      "step": 49500
    },
    {
      "epoch": 3.4376074252320383,
      "grad_norm": 20.625762939453125,
      "learning_rate": 6.249570299071846e-06,
      "loss": 0.4419,
      "step": 50000
    },
    {
      "epoch": 3.471983499484359,
      "grad_norm": 13.81946849822998,
      "learning_rate": 6.112066002062566e-06,
      "loss": 0.413,
      "step": 50500
    },
    {
      "epoch": 3.5063595737366793,
      "grad_norm": 22.7313175201416,
      "learning_rate": 5.974561705053283e-06,
      "loss": 0.457,
      "step": 51000
    },
    {
      "epoch": 3.5407356479889995,
      "grad_norm": 3.9714794158935547,
      "learning_rate": 5.837057408044003e-06,
      "loss": 0.4195,
      "step": 51500
    },
    {
      "epoch": 3.57511172224132,
      "grad_norm": 6.51727294921875,
      "learning_rate": 5.69955311103472e-06,
      "loss": 0.4209,
      "step": 52000
    },
    {
      "epoch": 3.6094877964936405,
      "grad_norm": 1.5519667863845825,
      "learning_rate": 5.5620488140254395e-06,
      "loss": 0.4234,
      "step": 52500
    },
    {
      "epoch": 3.6438638707459607,
      "grad_norm": 2.790830135345459,
      "learning_rate": 5.424544517016157e-06,
      "loss": 0.4051,
      "step": 53000
    },
    {
      "epoch": 3.678239944998281,
      "grad_norm": 16.141014099121094,
      "learning_rate": 5.287040220006876e-06,
      "loss": 0.4225,
      "step": 53500
    },
    {
      "epoch": 3.7126160192506017,
      "grad_norm": 15.742781639099121,
      "learning_rate": 5.149535922997594e-06,
      "loss": 0.44,
      "step": 54000
    },
    {
      "epoch": 3.746992093502922,
      "grad_norm": 4.725313186645508,
      "learning_rate": 5.012031625988312e-06,
      "loss": 0.4319,
      "step": 54500
    },
    {
      "epoch": 3.781368167755242,
      "grad_norm": 48.46257400512695,
      "learning_rate": 4.874527328979031e-06,
      "loss": 0.4236,
      "step": 55000
    },
    {
      "epoch": 3.815744242007563,
      "grad_norm": 7.854928016662598,
      "learning_rate": 4.737023031969749e-06,
      "loss": 0.4241,
      "step": 55500
    },
    {
      "epoch": 3.850120316259883,
      "grad_norm": 7.940547466278076,
      "learning_rate": 4.599518734960468e-06,
      "loss": 0.4485,
      "step": 56000
    },
    {
      "epoch": 3.8844963905122034,
      "grad_norm": 16.169157028198242,
      "learning_rate": 4.462014437951186e-06,
      "loss": 0.4018,
      "step": 56500
    },
    {
      "epoch": 3.918872464764524,
      "grad_norm": 17.712636947631836,
      "learning_rate": 4.324510140941905e-06,
      "loss": 0.4302,
      "step": 57000
    },
    {
      "epoch": 3.9532485390168444,
      "grad_norm": 10.8864164352417,
      "learning_rate": 4.187005843932623e-06,
      "loss": 0.4328,
      "step": 57500
    },
    {
      "epoch": 3.9876246132691646,
      "grad_norm": 23.81787109375,
      "learning_rate": 4.0495015469233416e-06,
      "loss": 0.4294,
      "step": 58000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.7286352698521829,
      "eval_f1": 0.7174073523423657,
      "eval_loss": 0.9503720998764038,
      "eval_precision": 0.720031386457187,
      "eval_recall": 0.7286352698521829,
      "eval_runtime": 221.0978,
      "eval_samples_per_second": 131.571,
      "eval_steps_per_second": 16.45,
      "step": 58180
    },
    {
      "epoch": 4.022000687521485,
      "grad_norm": 5.312537670135498,
      "learning_rate": 3.91199724991406e-06,
      "loss": 0.3732,
      "step": 58500
    },
    {
      "epoch": 4.056376761773805,
      "grad_norm": 1.3773692846298218,
      "learning_rate": 3.7744929529047784e-06,
      "loss": 0.3611,
      "step": 59000
    },
    {
      "epoch": 4.090752836026126,
      "grad_norm": 49.03903579711914,
      "learning_rate": 3.636988655895497e-06,
      "loss": 0.3552,
      "step": 59500
    },
    {
      "epoch": 4.1251289102784465,
      "grad_norm": 24.646129608154297,
      "learning_rate": 3.4994843588862153e-06,
      "loss": 0.3511,
      "step": 60000
    },
    {
      "epoch": 4.159504984530766,
      "grad_norm": 56.12127685546875,
      "learning_rate": 3.361980061876934e-06,
      "loss": 0.3726,
      "step": 60500
    },
    {
      "epoch": 4.193881058783087,
      "grad_norm": 1.979580283164978,
      "learning_rate": 3.2244757648676522e-06,
      "loss": 0.3582,
      "step": 61000
    },
    {
      "epoch": 4.228257133035408,
      "grad_norm": 9.996909141540527,
      "learning_rate": 3.0869714678583707e-06,
      "loss": 0.3559,
      "step": 61500
    },
    {
      "epoch": 4.2626332072877275,
      "grad_norm": 155.34890747070312,
      "learning_rate": 2.949467170849089e-06,
      "loss": 0.3497,
      "step": 62000
    },
    {
      "epoch": 4.297009281540048,
      "grad_norm": 4.1157941818237305,
      "learning_rate": 2.8119628738398076e-06,
      "loss": 0.3563,
      "step": 62500
    },
    {
      "epoch": 4.331385355792369,
      "grad_norm": 53.55501937866211,
      "learning_rate": 2.674458576830526e-06,
      "loss": 0.3847,
      "step": 63000
    },
    {
      "epoch": 4.365761430044689,
      "grad_norm": 11.193424224853516,
      "learning_rate": 2.536954279821245e-06,
      "loss": 0.376,
      "step": 63500
    },
    {
      "epoch": 4.4001375042970094,
      "grad_norm": 2.9857583045959473,
      "learning_rate": 2.399449982811963e-06,
      "loss": 0.3846,
      "step": 64000
    },
    {
      "epoch": 4.434513578549329,
      "grad_norm": 28.902889251708984,
      "learning_rate": 2.2619456858026814e-06,
      "loss": 0.3319,
      "step": 64500
    },
    {
      "epoch": 4.46888965280165,
      "grad_norm": 0.7780544757843018,
      "learning_rate": 2.1244413887934e-06,
      "loss": 0.3898,
      "step": 65000
    },
    {
      "epoch": 4.503265727053971,
      "grad_norm": 12.086007118225098,
      "learning_rate": 1.9869370917841187e-06,
      "loss": 0.3603,
      "step": 65500
    },
    {
      "epoch": 4.5376418013062905,
      "grad_norm": 32.04978561401367,
      "learning_rate": 1.849432794774837e-06,
      "loss": 0.3652,
      "step": 66000
    },
    {
      "epoch": 4.572017875558611,
      "grad_norm": 33.73926544189453,
      "learning_rate": 1.7119284977655554e-06,
      "loss": 0.3815,
      "step": 66500
    },
    {
      "epoch": 4.606393949810932,
      "grad_norm": 30.49285316467285,
      "learning_rate": 1.5744242007562738e-06,
      "loss": 0.3799,
      "step": 67000
    },
    {
      "epoch": 4.640770024063252,
      "grad_norm": 9.790465354919434,
      "learning_rate": 1.4369199037469923e-06,
      "loss": 0.3529,
      "step": 67500
    },
    {
      "epoch": 4.675146098315572,
      "grad_norm": 7.134939193725586,
      "learning_rate": 1.2994156067377107e-06,
      "loss": 0.3864,
      "step": 68000
    },
    {
      "epoch": 4.709522172567893,
      "grad_norm": 52.780006408691406,
      "learning_rate": 1.1619113097284292e-06,
      "loss": 0.3434,
      "step": 68500
    },
    {
      "epoch": 4.743898246820213,
      "grad_norm": 0.9341831207275391,
      "learning_rate": 1.0244070127191476e-06,
      "loss": 0.3751,
      "step": 69000
    },
    {
      "epoch": 4.778274321072534,
      "grad_norm": 0.7990444302558899,
      "learning_rate": 8.86902715709866e-07,
      "loss": 0.3422,
      "step": 69500
    },
    {
      "epoch": 4.812650395324854,
      "grad_norm": 3.2007668018341064,
      "learning_rate": 7.493984187005844e-07,
      "loss": 0.3646,
      "step": 70000
    },
    {
      "epoch": 4.847026469577174,
      "grad_norm": 33.289573669433594,
      "learning_rate": 6.118941216913028e-07,
      "loss": 0.3646,
      "step": 70500
    },
    {
      "epoch": 4.881402543829495,
      "grad_norm": 13.83192253112793,
      "learning_rate": 4.743898246820214e-07,
      "loss": 0.363,
      "step": 71000
    },
    {
      "epoch": 4.915778618081815,
      "grad_norm": 0.4164109230041504,
      "learning_rate": 3.368855276727398e-07,
      "loss": 0.3941,
      "step": 71500
    },
    {
      "epoch": 4.950154692334135,
      "grad_norm": 58.443817138671875,
      "learning_rate": 1.9938123066345824e-07,
      "loss": 0.3635,
      "step": 72000
    },
    {
      "epoch": 4.984530766586456,
      "grad_norm": 45.72999954223633,
      "learning_rate": 6.18769336541767e-08,
      "loss": 0.3733,
      "step": 72500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.724991405981437,
      "eval_f1": 0.7179783626994005,
      "eval_loss": 1.115433692932129,
      "eval_precision": 0.7171007699950122,
      "eval_recall": 0.724991405981437,
      "eval_runtime": 221.186,
      "eval_samples_per_second": 131.518,
      "eval_steps_per_second": 16.443,
      "step": 72725
    }
  ],
  "logging_steps": 500,
  "max_steps": 72725,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.182558432284279e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
