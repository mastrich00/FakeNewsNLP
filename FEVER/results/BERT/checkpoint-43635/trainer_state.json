{
  "best_metric": 0.7258508078377449,
  "best_model_checkpoint": "./results/BERT\\checkpoint-43635",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 43635,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.034376074252320386,
      "grad_norm": 6.716926574707031,
      "learning_rate": 1.986249570299072e-05,
      "loss": 1.0358,
      "step": 500
    },
    {
      "epoch": 0.06875214850464077,
      "grad_norm": 3.955193042755127,
      "learning_rate": 1.972499140598144e-05,
      "loss": 1.001,
      "step": 1000
    },
    {
      "epoch": 0.10312822275696115,
      "grad_norm": 5.565029144287109,
      "learning_rate": 1.9587487108972157e-05,
      "loss": 1.0066,
      "step": 1500
    },
    {
      "epoch": 0.13750429700928155,
      "grad_norm": 5.134533882141113,
      "learning_rate": 1.9449982811962875e-05,
      "loss": 0.9327,
      "step": 2000
    },
    {
      "epoch": 0.17188037126160194,
      "grad_norm": 22.12596321105957,
      "learning_rate": 1.9312478514953594e-05,
      "loss": 0.8785,
      "step": 2500
    },
    {
      "epoch": 0.2062564455139223,
      "grad_norm": 12.3390531539917,
      "learning_rate": 1.9174974217944312e-05,
      "loss": 0.8473,
      "step": 3000
    },
    {
      "epoch": 0.2406325197662427,
      "grad_norm": 7.342688083648682,
      "learning_rate": 1.903746992093503e-05,
      "loss": 0.8018,
      "step": 3500
    },
    {
      "epoch": 0.2750085940185631,
      "grad_norm": 8.59630298614502,
      "learning_rate": 1.889996562392575e-05,
      "loss": 0.7932,
      "step": 4000
    },
    {
      "epoch": 0.30938466827088346,
      "grad_norm": 6.38711404800415,
      "learning_rate": 1.8762461326916468e-05,
      "loss": 0.7712,
      "step": 4500
    },
    {
      "epoch": 0.3437607425232039,
      "grad_norm": 6.986225128173828,
      "learning_rate": 1.8624957029907186e-05,
      "loss": 0.777,
      "step": 5000
    },
    {
      "epoch": 0.37813681677552424,
      "grad_norm": 12.018972396850586,
      "learning_rate": 1.8487452732897905e-05,
      "loss": 0.7607,
      "step": 5500
    },
    {
      "epoch": 0.4125128910278446,
      "grad_norm": 9.312942504882812,
      "learning_rate": 1.8349948435888623e-05,
      "loss": 0.7672,
      "step": 6000
    },
    {
      "epoch": 0.44688896528016503,
      "grad_norm": 6.857250213623047,
      "learning_rate": 1.821244413887934e-05,
      "loss": 0.7591,
      "step": 6500
    },
    {
      "epoch": 0.4812650395324854,
      "grad_norm": 7.209392547607422,
      "learning_rate": 1.807493984187006e-05,
      "loss": 0.7258,
      "step": 7000
    },
    {
      "epoch": 0.5156411137848058,
      "grad_norm": 5.115551471710205,
      "learning_rate": 1.793743554486078e-05,
      "loss": 0.7288,
      "step": 7500
    },
    {
      "epoch": 0.5500171880371262,
      "grad_norm": 7.229748249053955,
      "learning_rate": 1.7799931247851497e-05,
      "loss": 0.7493,
      "step": 8000
    },
    {
      "epoch": 0.5843932622894465,
      "grad_norm": 10.635336875915527,
      "learning_rate": 1.7662426950842215e-05,
      "loss": 0.7421,
      "step": 8500
    },
    {
      "epoch": 0.6187693365417669,
      "grad_norm": 15.656001091003418,
      "learning_rate": 1.7524922653832934e-05,
      "loss": 0.7376,
      "step": 9000
    },
    {
      "epoch": 0.6531454107940873,
      "grad_norm": 8.284933090209961,
      "learning_rate": 1.7387418356823652e-05,
      "loss": 0.7571,
      "step": 9500
    },
    {
      "epoch": 0.6875214850464078,
      "grad_norm": 9.402363777160645,
      "learning_rate": 1.724991405981437e-05,
      "loss": 0.7158,
      "step": 10000
    },
    {
      "epoch": 0.7218975592987281,
      "grad_norm": 8.487504005432129,
      "learning_rate": 1.711240976280509e-05,
      "loss": 0.7343,
      "step": 10500
    },
    {
      "epoch": 0.7562736335510485,
      "grad_norm": 11.981077194213867,
      "learning_rate": 1.6974905465795807e-05,
      "loss": 0.7246,
      "step": 11000
    },
    {
      "epoch": 0.7906497078033689,
      "grad_norm": 9.31552505493164,
      "learning_rate": 1.6837401168786526e-05,
      "loss": 0.7278,
      "step": 11500
    },
    {
      "epoch": 0.8250257820556892,
      "grad_norm": 7.598433494567871,
      "learning_rate": 1.6699896871777244e-05,
      "loss": 0.74,
      "step": 12000
    },
    {
      "epoch": 0.8594018563080096,
      "grad_norm": 12.50836181640625,
      "learning_rate": 1.6562392574767963e-05,
      "loss": 0.7071,
      "step": 12500
    },
    {
      "epoch": 0.8937779305603301,
      "grad_norm": 8.784929275512695,
      "learning_rate": 1.642488827775868e-05,
      "loss": 0.7107,
      "step": 13000
    },
    {
      "epoch": 0.9281540048126504,
      "grad_norm": 6.197542667388916,
      "learning_rate": 1.62873839807494e-05,
      "loss": 0.728,
      "step": 13500
    },
    {
      "epoch": 0.9625300790649708,
      "grad_norm": 6.036182403564453,
      "learning_rate": 1.6149879683740118e-05,
      "loss": 0.7102,
      "step": 14000
    },
    {
      "epoch": 0.9969061533172912,
      "grad_norm": 5.161589622497559,
      "learning_rate": 1.6012375386730837e-05,
      "loss": 0.7149,
      "step": 14500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7134754211069096,
      "eval_f1": 0.6923169246531389,
      "eval_loss": 0.712267279624939,
      "eval_precision": 0.7108194422739738,
      "eval_recall": 0.7134754211069096,
      "eval_runtime": 223.1328,
      "eval_samples_per_second": 130.371,
      "eval_steps_per_second": 16.3,
      "step": 14545
    },
    {
      "epoch": 1.0312822275696116,
      "grad_norm": 19.153841018676758,
      "learning_rate": 1.5874871089721555e-05,
      "loss": 0.6266,
      "step": 15000
    },
    {
      "epoch": 1.0656583018219319,
      "grad_norm": 4.325503349304199,
      "learning_rate": 1.5737366792712274e-05,
      "loss": 0.6367,
      "step": 15500
    },
    {
      "epoch": 1.1000343760742524,
      "grad_norm": 7.257952690124512,
      "learning_rate": 1.5599862495702992e-05,
      "loss": 0.6298,
      "step": 16000
    },
    {
      "epoch": 1.1344104503265726,
      "grad_norm": 15.629335403442383,
      "learning_rate": 1.546235819869371e-05,
      "loss": 0.6197,
      "step": 16500
    },
    {
      "epoch": 1.168786524578893,
      "grad_norm": 22.254581451416016,
      "learning_rate": 1.532485390168443e-05,
      "loss": 0.6303,
      "step": 17000
    },
    {
      "epoch": 1.2031625988312136,
      "grad_norm": 12.377492904663086,
      "learning_rate": 1.5187349604675147e-05,
      "loss": 0.6301,
      "step": 17500
    },
    {
      "epoch": 1.2375386730835338,
      "grad_norm": 17.517919540405273,
      "learning_rate": 1.5049845307665867e-05,
      "loss": 0.6183,
      "step": 18000
    },
    {
      "epoch": 1.2719147473358543,
      "grad_norm": 5.9277801513671875,
      "learning_rate": 1.4912341010656584e-05,
      "loss": 0.6502,
      "step": 18500
    },
    {
      "epoch": 1.3062908215881746,
      "grad_norm": 7.85957145690918,
      "learning_rate": 1.4774836713647303e-05,
      "loss": 0.6107,
      "step": 19000
    },
    {
      "epoch": 1.340666895840495,
      "grad_norm": 18.657743453979492,
      "learning_rate": 1.4637332416638021e-05,
      "loss": 0.6515,
      "step": 19500
    },
    {
      "epoch": 1.3750429700928155,
      "grad_norm": 7.289359092712402,
      "learning_rate": 1.4499828119628741e-05,
      "loss": 0.6208,
      "step": 20000
    },
    {
      "epoch": 1.4094190443451358,
      "grad_norm": 6.286043643951416,
      "learning_rate": 1.4362323822619458e-05,
      "loss": 0.6387,
      "step": 20500
    },
    {
      "epoch": 1.4437951185974562,
      "grad_norm": 24.47428321838379,
      "learning_rate": 1.4224819525610176e-05,
      "loss": 0.6127,
      "step": 21000
    },
    {
      "epoch": 1.4781711928497765,
      "grad_norm": 7.881985187530518,
      "learning_rate": 1.4087315228600895e-05,
      "loss": 0.632,
      "step": 21500
    },
    {
      "epoch": 1.512547267102097,
      "grad_norm": 7.44713020324707,
      "learning_rate": 1.3949810931591613e-05,
      "loss": 0.6152,
      "step": 22000
    },
    {
      "epoch": 1.5469233413544172,
      "grad_norm": 14.446290969848633,
      "learning_rate": 1.381230663458233e-05,
      "loss": 0.6155,
      "step": 22500
    },
    {
      "epoch": 1.5812994156067377,
      "grad_norm": 10.430439949035645,
      "learning_rate": 1.367480233757305e-05,
      "loss": 0.6413,
      "step": 23000
    },
    {
      "epoch": 1.6156754898590582,
      "grad_norm": 7.244133949279785,
      "learning_rate": 1.3537298040563769e-05,
      "loss": 0.6303,
      "step": 23500
    },
    {
      "epoch": 1.6500515641113784,
      "grad_norm": 6.176677227020264,
      "learning_rate": 1.3399793743554487e-05,
      "loss": 0.6272,
      "step": 24000
    },
    {
      "epoch": 1.684427638363699,
      "grad_norm": 5.93399715423584,
      "learning_rate": 1.3262289446545204e-05,
      "loss": 0.6389,
      "step": 24500
    },
    {
      "epoch": 1.7188037126160194,
      "grad_norm": 10.051980972290039,
      "learning_rate": 1.3124785149535924e-05,
      "loss": 0.6409,
      "step": 25000
    },
    {
      "epoch": 1.7531797868683396,
      "grad_norm": 12.901071548461914,
      "learning_rate": 1.2987280852526642e-05,
      "loss": 0.6155,
      "step": 25500
    },
    {
      "epoch": 1.78755586112066,
      "grad_norm": 11.651710510253906,
      "learning_rate": 1.2849776555517361e-05,
      "loss": 0.6444,
      "step": 26000
    },
    {
      "epoch": 1.8219319353729804,
      "grad_norm": 19.174549102783203,
      "learning_rate": 1.2712272258508081e-05,
      "loss": 0.6069,
      "step": 26500
    },
    {
      "epoch": 1.8563080096253008,
      "grad_norm": 8.611261367797852,
      "learning_rate": 1.2574767961498798e-05,
      "loss": 0.6139,
      "step": 27000
    },
    {
      "epoch": 1.890684083877621,
      "grad_norm": 11.21539306640625,
      "learning_rate": 1.2437263664489516e-05,
      "loss": 0.6144,
      "step": 27500
    },
    {
      "epoch": 1.9250601581299416,
      "grad_norm": 7.609725475311279,
      "learning_rate": 1.2299759367480235e-05,
      "loss": 0.6202,
      "step": 28000
    },
    {
      "epoch": 1.959436232382262,
      "grad_norm": 13.300559997558594,
      "learning_rate": 1.2162255070470955e-05,
      "loss": 0.6263,
      "step": 28500
    },
    {
      "epoch": 1.9938123066345823,
      "grad_norm": 14.154826164245605,
      "learning_rate": 1.2024750773461672e-05,
      "loss": 0.6402,
      "step": 29000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.7244070127191474,
      "eval_f1": 0.7106493954582759,
      "eval_loss": 0.6939932703971863,
      "eval_precision": 0.7202417494561286,
      "eval_recall": 0.7244070127191474,
      "eval_runtime": 221.0908,
      "eval_samples_per_second": 131.575,
      "eval_steps_per_second": 16.45,
      "step": 29090
    },
    {
      "epoch": 2.0281883808869026,
      "grad_norm": 24.78409767150879,
      "learning_rate": 1.188724647645239e-05,
      "loss": 0.521,
      "step": 29500
    },
    {
      "epoch": 2.0625644551392233,
      "grad_norm": 13.156150817871094,
      "learning_rate": 1.1749742179443108e-05,
      "loss": 0.5265,
      "step": 30000
    },
    {
      "epoch": 2.0969405293915435,
      "grad_norm": 19.256513595581055,
      "learning_rate": 1.1612237882433827e-05,
      "loss": 0.5139,
      "step": 30500
    },
    {
      "epoch": 2.1313166036438638,
      "grad_norm": 6.107081890106201,
      "learning_rate": 1.1474733585424544e-05,
      "loss": 0.4973,
      "step": 31000
    },
    {
      "epoch": 2.1656926778961845,
      "grad_norm": 4.252411365509033,
      "learning_rate": 1.1337229288415264e-05,
      "loss": 0.5136,
      "step": 31500
    },
    {
      "epoch": 2.2000687521485047,
      "grad_norm": 9.913244247436523,
      "learning_rate": 1.1199724991405982e-05,
      "loss": 0.5057,
      "step": 32000
    },
    {
      "epoch": 2.234444826400825,
      "grad_norm": 15.54327392578125,
      "learning_rate": 1.10622206943967e-05,
      "loss": 0.5245,
      "step": 32500
    },
    {
      "epoch": 2.2688209006531452,
      "grad_norm": 8.82065486907959,
      "learning_rate": 1.0924716397387417e-05,
      "loss": 0.4998,
      "step": 33000
    },
    {
      "epoch": 2.303196974905466,
      "grad_norm": 7.988988399505615,
      "learning_rate": 1.0787212100378138e-05,
      "loss": 0.5212,
      "step": 33500
    },
    {
      "epoch": 2.337573049157786,
      "grad_norm": 2.7917914390563965,
      "learning_rate": 1.0649707803368856e-05,
      "loss": 0.5061,
      "step": 34000
    },
    {
      "epoch": 2.3719491234101064,
      "grad_norm": 17.696128845214844,
      "learning_rate": 1.0512203506359575e-05,
      "loss": 0.5065,
      "step": 34500
    },
    {
      "epoch": 2.406325197662427,
      "grad_norm": 25.201858520507812,
      "learning_rate": 1.0374699209350295e-05,
      "loss": 0.5202,
      "step": 35000
    },
    {
      "epoch": 2.4407012719147474,
      "grad_norm": 15.131303787231445,
      "learning_rate": 1.0237194912341011e-05,
      "loss": 0.5194,
      "step": 35500
    },
    {
      "epoch": 2.4750773461670676,
      "grad_norm": 31.719457626342773,
      "learning_rate": 1.009969061533173e-05,
      "loss": 0.4984,
      "step": 36000
    },
    {
      "epoch": 2.509453420419388,
      "grad_norm": 13.601419448852539,
      "learning_rate": 9.962186318322448e-06,
      "loss": 0.5267,
      "step": 36500
    },
    {
      "epoch": 2.5438294946717086,
      "grad_norm": 7.048270225524902,
      "learning_rate": 9.824682021313167e-06,
      "loss": 0.5166,
      "step": 37000
    },
    {
      "epoch": 2.578205568924029,
      "grad_norm": 16.185571670532227,
      "learning_rate": 9.687177724303885e-06,
      "loss": 0.5246,
      "step": 37500
    },
    {
      "epoch": 2.612581643176349,
      "grad_norm": 28.36086082458496,
      "learning_rate": 9.549673427294604e-06,
      "loss": 0.5112,
      "step": 38000
    },
    {
      "epoch": 2.64695771742867,
      "grad_norm": 8.331846237182617,
      "learning_rate": 9.412169130285322e-06,
      "loss": 0.534,
      "step": 38500
    },
    {
      "epoch": 2.68133379168099,
      "grad_norm": 28.283761978149414,
      "learning_rate": 9.27466483327604e-06,
      "loss": 0.5093,
      "step": 39000
    },
    {
      "epoch": 2.7157098659333103,
      "grad_norm": 9.442763328552246,
      "learning_rate": 9.137160536266759e-06,
      "loss": 0.5226,
      "step": 39500
    },
    {
      "epoch": 2.750085940185631,
      "grad_norm": 15.027939796447754,
      "learning_rate": 8.999656239257477e-06,
      "loss": 0.5243,
      "step": 40000
    },
    {
      "epoch": 2.7844620144379513,
      "grad_norm": 19.337003707885742,
      "learning_rate": 8.862151942248196e-06,
      "loss": 0.5217,
      "step": 40500
    },
    {
      "epoch": 2.8188380886902715,
      "grad_norm": 7.054086685180664,
      "learning_rate": 8.724647645238914e-06,
      "loss": 0.5079,
      "step": 41000
    },
    {
      "epoch": 2.8532141629425922,
      "grad_norm": 25.773786544799805,
      "learning_rate": 8.587143348229633e-06,
      "loss": 0.5195,
      "step": 41500
    },
    {
      "epoch": 2.8875902371949125,
      "grad_norm": 3.587148666381836,
      "learning_rate": 8.449639051220351e-06,
      "loss": 0.5354,
      "step": 42000
    },
    {
      "epoch": 2.9219663114472327,
      "grad_norm": 8.426344871520996,
      "learning_rate": 8.31213475421107e-06,
      "loss": 0.4923,
      "step": 42500
    },
    {
      "epoch": 2.956342385699553,
      "grad_norm": 12.403528213500977,
      "learning_rate": 8.174630457201788e-06,
      "loss": 0.5108,
      "step": 43000
    },
    {
      "epoch": 2.9907184599518732,
      "grad_norm": 15.141791343688965,
      "learning_rate": 8.037126160192507e-06,
      "loss": 0.5415,
      "step": 43500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.7258508078377449,
      "eval_f1": 0.7150497822254791,
      "eval_loss": 0.8002759218215942,
      "eval_precision": 0.7175797162795315,
      "eval_recall": 0.7258508078377449,
      "eval_runtime": 221.1199,
      "eval_samples_per_second": 131.558,
      "eval_steps_per_second": 16.448,
      "step": 43635
    }
  ],
  "logging_steps": 500,
  "max_steps": 72725,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3095350593705674e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
