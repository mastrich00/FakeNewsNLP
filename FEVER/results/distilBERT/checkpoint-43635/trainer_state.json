{
  "best_metric": 0.7224475764867652,
  "best_model_checkpoint": "./results/distilBERT\\checkpoint-29090",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 43635,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.034376074252320386,
      "grad_norm": 1.8347618579864502,
      "learning_rate": 1.9770826171651198e-05,
      "loss": 1.0195,
      "step": 500
    },
    {
      "epoch": 0.06875214850464077,
      "grad_norm": 1.6486629247665405,
      "learning_rate": 1.9541652343302398e-05,
      "loss": 0.9494,
      "step": 1000
    },
    {
      "epoch": 0.10312822275696115,
      "grad_norm": 5.027825832366943,
      "learning_rate": 1.9312478514953594e-05,
      "loss": 0.8822,
      "step": 1500
    },
    {
      "epoch": 0.13750429700928155,
      "grad_norm": 3.448559045791626,
      "learning_rate": 1.908330468660479e-05,
      "loss": 0.8509,
      "step": 2000
    },
    {
      "epoch": 0.17188037126160194,
      "grad_norm": 10.801177978515625,
      "learning_rate": 1.8854130858255986e-05,
      "loss": 0.8167,
      "step": 2500
    },
    {
      "epoch": 0.2062564455139223,
      "grad_norm": 5.7373366355896,
      "learning_rate": 1.8624957029907186e-05,
      "loss": 0.8183,
      "step": 3000
    },
    {
      "epoch": 0.2406325197662427,
      "grad_norm": 4.304917812347412,
      "learning_rate": 1.8395783201558382e-05,
      "loss": 0.7783,
      "step": 3500
    },
    {
      "epoch": 0.2750085940185631,
      "grad_norm": 7.55387544631958,
      "learning_rate": 1.8166609373209582e-05,
      "loss": 0.793,
      "step": 4000
    },
    {
      "epoch": 0.30938466827088346,
      "grad_norm": 5.87196159362793,
      "learning_rate": 1.793743554486078e-05,
      "loss": 0.7751,
      "step": 4500
    },
    {
      "epoch": 0.3437607425232039,
      "grad_norm": 5.399232387542725,
      "learning_rate": 1.7708261716511978e-05,
      "loss": 0.7727,
      "step": 5000
    },
    {
      "epoch": 0.37813681677552424,
      "grad_norm": 6.8097920417785645,
      "learning_rate": 1.7479087888163174e-05,
      "loss": 0.7586,
      "step": 5500
    },
    {
      "epoch": 0.4125128910278446,
      "grad_norm": 4.657532691955566,
      "learning_rate": 1.724991405981437e-05,
      "loss": 0.7739,
      "step": 6000
    },
    {
      "epoch": 0.44688896528016503,
      "grad_norm": 6.50102424621582,
      "learning_rate": 1.702074023146557e-05,
      "loss": 0.7614,
      "step": 6500
    },
    {
      "epoch": 0.4812650395324854,
      "grad_norm": 4.698307991027832,
      "learning_rate": 1.6791566403116767e-05,
      "loss": 0.7365,
      "step": 7000
    },
    {
      "epoch": 0.5156411137848058,
      "grad_norm": 5.597908020019531,
      "learning_rate": 1.6562392574767963e-05,
      "loss": 0.7457,
      "step": 7500
    },
    {
      "epoch": 0.5500171880371262,
      "grad_norm": 6.415862083435059,
      "learning_rate": 1.633321874641916e-05,
      "loss": 0.7591,
      "step": 8000
    },
    {
      "epoch": 0.5843932622894465,
      "grad_norm": 10.74989128112793,
      "learning_rate": 1.610404491807036e-05,
      "loss": 0.7465,
      "step": 8500
    },
    {
      "epoch": 0.6187693365417669,
      "grad_norm": 8.312018394470215,
      "learning_rate": 1.5874871089721555e-05,
      "loss": 0.7389,
      "step": 9000
    },
    {
      "epoch": 0.6531454107940873,
      "grad_norm": 7.887161731719971,
      "learning_rate": 1.564569726137275e-05,
      "loss": 0.7594,
      "step": 9500
    },
    {
      "epoch": 0.6875214850464078,
      "grad_norm": 7.6948089599609375,
      "learning_rate": 1.5416523433023948e-05,
      "loss": 0.7349,
      "step": 10000
    },
    {
      "epoch": 0.7218975592987281,
      "grad_norm": 7.805572986602783,
      "learning_rate": 1.5187349604675147e-05,
      "loss": 0.7338,
      "step": 10500
    },
    {
      "epoch": 0.7562736335510485,
      "grad_norm": 6.303680419921875,
      "learning_rate": 1.4958175776326345e-05,
      "loss": 0.728,
      "step": 11000
    },
    {
      "epoch": 0.7906497078033689,
      "grad_norm": 16.014366149902344,
      "learning_rate": 1.4729001947977542e-05,
      "loss": 0.7377,
      "step": 11500
    },
    {
      "epoch": 0.8250257820556892,
      "grad_norm": 4.675284385681152,
      "learning_rate": 1.4499828119628741e-05,
      "loss": 0.7449,
      "step": 12000
    },
    {
      "epoch": 0.8594018563080096,
      "grad_norm": 9.862503051757812,
      "learning_rate": 1.4270654291279938e-05,
      "loss": 0.7138,
      "step": 12500
    },
    {
      "epoch": 0.8937779305603301,
      "grad_norm": 4.214314937591553,
      "learning_rate": 1.4041480462931134e-05,
      "loss": 0.7092,
      "step": 13000
    },
    {
      "epoch": 0.9281540048126504,
      "grad_norm": 10.235660552978516,
      "learning_rate": 1.381230663458233e-05,
      "loss": 0.7338,
      "step": 13500
    },
    {
      "epoch": 0.9625300790649708,
      "grad_norm": 6.593048095703125,
      "learning_rate": 1.358313280623353e-05,
      "loss": 0.7139,
      "step": 14000
    },
    {
      "epoch": 0.9969061533172912,
      "grad_norm": 3.7102675437927246,
      "learning_rate": 1.3353958977884726e-05,
      "loss": 0.7276,
      "step": 14500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7086627707115848,
      "eval_f1": 0.6879222884449324,
      "eval_loss": 0.7072781920433044,
      "eval_precision": 0.7045423562869886,
      "eval_recall": 0.7086627707115848,
      "eval_runtime": 110.8467,
      "eval_samples_per_second": 262.435,
      "eval_steps_per_second": 32.811,
      "step": 14545
    },
    {
      "epoch": 1.0312822275696116,
      "grad_norm": 9.2540922164917,
      "learning_rate": 1.3124785149535924e-05,
      "loss": 0.6392,
      "step": 15000
    },
    {
      "epoch": 1.0656583018219319,
      "grad_norm": 2.856821298599243,
      "learning_rate": 1.2895611321187122e-05,
      "loss": 0.6541,
      "step": 15500
    },
    {
      "epoch": 1.1000343760742524,
      "grad_norm": 8.777643203735352,
      "learning_rate": 1.266643749283832e-05,
      "loss": 0.6529,
      "step": 16000
    },
    {
      "epoch": 1.1344104503265726,
      "grad_norm": 11.759468078613281,
      "learning_rate": 1.2437263664489516e-05,
      "loss": 0.6349,
      "step": 16500
    },
    {
      "epoch": 1.168786524578893,
      "grad_norm": 11.507981300354004,
      "learning_rate": 1.2208089836140713e-05,
      "loss": 0.6508,
      "step": 17000
    },
    {
      "epoch": 1.2031625988312136,
      "grad_norm": 8.934078216552734,
      "learning_rate": 1.1978916007791912e-05,
      "loss": 0.6441,
      "step": 17500
    },
    {
      "epoch": 1.2375386730835338,
      "grad_norm": 9.180818557739258,
      "learning_rate": 1.1749742179443108e-05,
      "loss": 0.6266,
      "step": 18000
    },
    {
      "epoch": 1.2719147473358543,
      "grad_norm": 6.5056471824646,
      "learning_rate": 1.1520568351094305e-05,
      "loss": 0.6695,
      "step": 18500
    },
    {
      "epoch": 1.3062908215881746,
      "grad_norm": 3.4084298610687256,
      "learning_rate": 1.1291394522745503e-05,
      "loss": 0.614,
      "step": 19000
    },
    {
      "epoch": 1.340666895840495,
      "grad_norm": 11.612316131591797,
      "learning_rate": 1.10622206943967e-05,
      "loss": 0.6557,
      "step": 19500
    },
    {
      "epoch": 1.3750429700928155,
      "grad_norm": 4.081873416900635,
      "learning_rate": 1.0833046866047899e-05,
      "loss": 0.6355,
      "step": 20000
    },
    {
      "epoch": 1.4094190443451358,
      "grad_norm": 9.81577205657959,
      "learning_rate": 1.0603873037699095e-05,
      "loss": 0.65,
      "step": 20500
    },
    {
      "epoch": 1.4437951185974562,
      "grad_norm": 8.519082069396973,
      "learning_rate": 1.0374699209350295e-05,
      "loss": 0.6361,
      "step": 21000
    },
    {
      "epoch": 1.4781711928497765,
      "grad_norm": 6.321630954742432,
      "learning_rate": 1.0145525381001491e-05,
      "loss": 0.6422,
      "step": 21500
    },
    {
      "epoch": 1.512547267102097,
      "grad_norm": 5.884603500366211,
      "learning_rate": 9.916351552652687e-06,
      "loss": 0.6259,
      "step": 22000
    },
    {
      "epoch": 1.5469233413544172,
      "grad_norm": 16.942718505859375,
      "learning_rate": 9.687177724303885e-06,
      "loss": 0.6202,
      "step": 22500
    },
    {
      "epoch": 1.5812994156067377,
      "grad_norm": 6.9442596435546875,
      "learning_rate": 9.458003895955083e-06,
      "loss": 0.6369,
      "step": 23000
    },
    {
      "epoch": 1.6156754898590582,
      "grad_norm": 5.303411960601807,
      "learning_rate": 9.22883006760628e-06,
      "loss": 0.6349,
      "step": 23500
    },
    {
      "epoch": 1.6500515641113784,
      "grad_norm": 5.677845478057861,
      "learning_rate": 8.999656239257477e-06,
      "loss": 0.6396,
      "step": 24000
    },
    {
      "epoch": 1.684427638363699,
      "grad_norm": 6.1572418212890625,
      "learning_rate": 8.770482410908675e-06,
      "loss": 0.6463,
      "step": 24500
    },
    {
      "epoch": 1.7188037126160194,
      "grad_norm": 6.719292640686035,
      "learning_rate": 8.541308582559872e-06,
      "loss": 0.6446,
      "step": 25000
    },
    {
      "epoch": 1.7531797868683396,
      "grad_norm": 10.57198715209961,
      "learning_rate": 8.31213475421107e-06,
      "loss": 0.6255,
      "step": 25500
    },
    {
      "epoch": 1.78755586112066,
      "grad_norm": 11.317973136901855,
      "learning_rate": 8.082960925862268e-06,
      "loss": 0.6429,
      "step": 26000
    },
    {
      "epoch": 1.8219319353729804,
      "grad_norm": 6.923401832580566,
      "learning_rate": 7.853787097513464e-06,
      "loss": 0.6237,
      "step": 26500
    },
    {
      "epoch": 1.8563080096253008,
      "grad_norm": 23.160564422607422,
      "learning_rate": 7.624613269164663e-06,
      "loss": 0.6193,
      "step": 27000
    },
    {
      "epoch": 1.890684083877621,
      "grad_norm": 15.16767406463623,
      "learning_rate": 7.395439440815859e-06,
      "loss": 0.6145,
      "step": 27500
    },
    {
      "epoch": 1.9250601581299416,
      "grad_norm": 13.581724166870117,
      "learning_rate": 7.166265612467057e-06,
      "loss": 0.6328,
      "step": 28000
    },
    {
      "epoch": 1.959436232382262,
      "grad_norm": 4.573030471801758,
      "learning_rate": 6.937091784118254e-06,
      "loss": 0.6341,
      "step": 28500
    },
    {
      "epoch": 1.9938123066345823,
      "grad_norm": 7.801246643066406,
      "learning_rate": 6.707917955769452e-06,
      "loss": 0.6381,
      "step": 29000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.7224475764867652,
      "eval_f1": 0.7083033582700049,
      "eval_loss": 0.6934328079223633,
      "eval_precision": 0.7174598661692245,
      "eval_recall": 0.7224475764867652,
      "eval_runtime": 111.5537,
      "eval_samples_per_second": 260.771,
      "eval_steps_per_second": 32.603,
      "step": 29090
    },
    {
      "epoch": 2.0281883808869026,
      "grad_norm": 5.043487071990967,
      "learning_rate": 6.478744127420648e-06,
      "loss": 0.5504,
      "step": 29500
    },
    {
      "epoch": 2.0625644551392233,
      "grad_norm": 10.030744552612305,
      "learning_rate": 6.249570299071846e-06,
      "loss": 0.55,
      "step": 30000
    },
    {
      "epoch": 2.0969405293915435,
      "grad_norm": 19.543371200561523,
      "learning_rate": 6.020396470723044e-06,
      "loss": 0.5399,
      "step": 30500
    },
    {
      "epoch": 2.1313166036438638,
      "grad_norm": 12.638469696044922,
      "learning_rate": 5.7912226423742415e-06,
      "loss": 0.5222,
      "step": 31000
    },
    {
      "epoch": 2.1656926778961845,
      "grad_norm": 8.999076843261719,
      "learning_rate": 5.5620488140254395e-06,
      "loss": 0.5558,
      "step": 31500
    },
    {
      "epoch": 2.2000687521485047,
      "grad_norm": 10.112792015075684,
      "learning_rate": 5.332874985676636e-06,
      "loss": 0.5401,
      "step": 32000
    },
    {
      "epoch": 2.234444826400825,
      "grad_norm": 12.032600402832031,
      "learning_rate": 5.103701157327834e-06,
      "loss": 0.5504,
      "step": 32500
    },
    {
      "epoch": 2.2688209006531452,
      "grad_norm": 20.4188232421875,
      "learning_rate": 4.874527328979031e-06,
      "loss": 0.5344,
      "step": 33000
    },
    {
      "epoch": 2.303196974905466,
      "grad_norm": 14.084407806396484,
      "learning_rate": 4.645353500630229e-06,
      "loss": 0.5536,
      "step": 33500
    },
    {
      "epoch": 2.337573049157786,
      "grad_norm": 2.939516305923462,
      "learning_rate": 4.416179672281426e-06,
      "loss": 0.5239,
      "step": 34000
    },
    {
      "epoch": 2.3719491234101064,
      "grad_norm": 23.620563507080078,
      "learning_rate": 4.187005843932623e-06,
      "loss": 0.5257,
      "step": 34500
    },
    {
      "epoch": 2.406325197662427,
      "grad_norm": 8.614375114440918,
      "learning_rate": 3.957832015583821e-06,
      "loss": 0.5472,
      "step": 35000
    },
    {
      "epoch": 2.4407012719147474,
      "grad_norm": 13.614081382751465,
      "learning_rate": 3.728658187235018e-06,
      "loss": 0.5569,
      "step": 35500
    },
    {
      "epoch": 2.4750773461670676,
      "grad_norm": 8.822793960571289,
      "learning_rate": 3.4994843588862153e-06,
      "loss": 0.5259,
      "step": 36000
    },
    {
      "epoch": 2.509453420419388,
      "grad_norm": 10.04028606414795,
      "learning_rate": 3.270310530537413e-06,
      "loss": 0.5355,
      "step": 36500
    },
    {
      "epoch": 2.5438294946717086,
      "grad_norm": 13.071097373962402,
      "learning_rate": 3.04113670218861e-06,
      "loss": 0.53,
      "step": 37000
    },
    {
      "epoch": 2.578205568924029,
      "grad_norm": 14.306991577148438,
      "learning_rate": 2.8119628738398076e-06,
      "loss": 0.5345,
      "step": 37500
    },
    {
      "epoch": 2.612581643176349,
      "grad_norm": 16.793476104736328,
      "learning_rate": 2.5827890454910056e-06,
      "loss": 0.5186,
      "step": 38000
    },
    {
      "epoch": 2.64695771742867,
      "grad_norm": 9.93034553527832,
      "learning_rate": 2.3536152171422027e-06,
      "loss": 0.5461,
      "step": 38500
    },
    {
      "epoch": 2.68133379168099,
      "grad_norm": 9.605915069580078,
      "learning_rate": 2.1244413887934e-06,
      "loss": 0.5276,
      "step": 39000
    },
    {
      "epoch": 2.7157098659333103,
      "grad_norm": 33.94557189941406,
      "learning_rate": 1.8952675604445976e-06,
      "loss": 0.5419,
      "step": 39500
    },
    {
      "epoch": 2.750085940185631,
      "grad_norm": 19.996089935302734,
      "learning_rate": 1.666093732095795e-06,
      "loss": 0.5354,
      "step": 40000
    },
    {
      "epoch": 2.7844620144379513,
      "grad_norm": 20.257999420166016,
      "learning_rate": 1.4369199037469923e-06,
      "loss": 0.5419,
      "step": 40500
    },
    {
      "epoch": 2.8188380886902715,
      "grad_norm": 4.888258934020996,
      "learning_rate": 1.2077460753981896e-06,
      "loss": 0.5297,
      "step": 41000
    },
    {
      "epoch": 2.8532141629425922,
      "grad_norm": 11.0606107711792,
      "learning_rate": 9.78572247049387e-07,
      "loss": 0.5312,
      "step": 41500
    },
    {
      "epoch": 2.8875902371949125,
      "grad_norm": 9.988885879516602,
      "learning_rate": 7.493984187005844e-07,
      "loss": 0.5452,
      "step": 42000
    },
    {
      "epoch": 2.9219663114472327,
      "grad_norm": 7.153026580810547,
      "learning_rate": 5.202245903517818e-07,
      "loss": 0.5006,
      "step": 42500
    },
    {
      "epoch": 2.956342385699553,
      "grad_norm": 23.973873138427734,
      "learning_rate": 2.910507620029793e-07,
      "loss": 0.5303,
      "step": 43000
    },
    {
      "epoch": 2.9907184599518732,
      "grad_norm": 11.85821533203125,
      "learning_rate": 6.18769336541767e-08,
      "loss": 0.5415,
      "step": 43500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.7220694396699897,
      "eval_f1": 0.712038538239763,
      "eval_loss": 0.7399428486824036,
      "eval_precision": 0.7141062959850009,
      "eval_recall": 0.7220694396699897,
      "eval_runtime": 111.0035,
      "eval_samples_per_second": 262.064,
      "eval_steps_per_second": 32.765,
      "step": 43635
    }
  ],
  "logging_steps": 500,
  "max_steps": 43635,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6593118582295242.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
