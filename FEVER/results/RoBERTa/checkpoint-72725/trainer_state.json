{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 72725,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.034376074252320386,
      "grad_norm": 2.8225648403167725,
      "learning_rate": 1.986249570299072e-05,
      "loss": 1.0234,
      "step": 500
    },
    {
      "epoch": 0.06875214850464077,
      "grad_norm": 2.5648534297943115,
      "learning_rate": 1.972499140598144e-05,
      "loss": 0.9994,
      "step": 1000
    },
    {
      "epoch": 0.10312822275696115,
      "grad_norm": 2.735701084136963,
      "learning_rate": 1.9587487108972157e-05,
      "loss": 1.0092,
      "step": 1500
    },
    {
      "epoch": 0.13750429700928155,
      "grad_norm": 3.124971866607666,
      "learning_rate": 1.9449982811962875e-05,
      "loss": 1.0164,
      "step": 2000
    },
    {
      "epoch": 0.17188037126160194,
      "grad_norm": 5.744596004486084,
      "learning_rate": 1.9312478514953594e-05,
      "loss": 1.0052,
      "step": 2500
    },
    {
      "epoch": 0.2062564455139223,
      "grad_norm": 3.1049482822418213,
      "learning_rate": 1.9174974217944312e-05,
      "loss": 1.0165,
      "step": 3000
    },
    {
      "epoch": 0.2406325197662427,
      "grad_norm": 1.1530494689941406,
      "learning_rate": 1.903746992093503e-05,
      "loss": 1.0001,
      "step": 3500
    },
    {
      "epoch": 0.2750085940185631,
      "grad_norm": 3.772066593170166,
      "learning_rate": 1.889996562392575e-05,
      "loss": 0.9912,
      "step": 4000
    },
    {
      "epoch": 0.30938466827088346,
      "grad_norm": 2.838623046875,
      "learning_rate": 1.8762461326916468e-05,
      "loss": 1.0038,
      "step": 4500
    },
    {
      "epoch": 0.3437607425232039,
      "grad_norm": 1.2637457847595215,
      "learning_rate": 1.8624957029907186e-05,
      "loss": 1.0118,
      "step": 5000
    },
    {
      "epoch": 0.37813681677552424,
      "grad_norm": 3.8070435523986816,
      "learning_rate": 1.8487452732897905e-05,
      "loss": 0.9857,
      "step": 5500
    },
    {
      "epoch": 0.4125128910278446,
      "grad_norm": 2.4872193336486816,
      "learning_rate": 1.8349948435888623e-05,
      "loss": 1.007,
      "step": 6000
    },
    {
      "epoch": 0.44688896528016503,
      "grad_norm": 2.4923129081726074,
      "learning_rate": 1.821244413887934e-05,
      "loss": 0.9921,
      "step": 6500
    },
    {
      "epoch": 0.4812650395324854,
      "grad_norm": 3.497436046600342,
      "learning_rate": 1.807493984187006e-05,
      "loss": 1.003,
      "step": 7000
    },
    {
      "epoch": 0.5156411137848058,
      "grad_norm": 1.5217808485031128,
      "learning_rate": 1.793743554486078e-05,
      "loss": 1.003,
      "step": 7500
    },
    {
      "epoch": 0.5500171880371262,
      "grad_norm": 2.73038387298584,
      "learning_rate": 1.7799931247851497e-05,
      "loss": 1.01,
      "step": 8000
    },
    {
      "epoch": 0.5843932622894465,
      "grad_norm": 4.426019191741943,
      "learning_rate": 1.7662426950842215e-05,
      "loss": 1.0081,
      "step": 8500
    },
    {
      "epoch": 0.6187693365417669,
      "grad_norm": 1.036871314048767,
      "learning_rate": 1.7524922653832934e-05,
      "loss": 1.002,
      "step": 9000
    },
    {
      "epoch": 0.6531454107940873,
      "grad_norm": 1.5387498140335083,
      "learning_rate": 1.7387418356823652e-05,
      "loss": 1.0053,
      "step": 9500
    },
    {
      "epoch": 0.6875214850464078,
      "grad_norm": 2.89290189743042,
      "learning_rate": 1.724991405981437e-05,
      "loss": 0.9896,
      "step": 10000
    },
    {
      "epoch": 0.7218975592987281,
      "grad_norm": 2.225259780883789,
      "learning_rate": 1.711240976280509e-05,
      "loss": 0.9952,
      "step": 10500
    },
    {
      "epoch": 0.7562736335510485,
      "grad_norm": 4.015224933624268,
      "learning_rate": 1.6974905465795807e-05,
      "loss": 1.0012,
      "step": 11000
    },
    {
      "epoch": 0.7906497078033689,
      "grad_norm": 3.5269699096679688,
      "learning_rate": 1.6837401168786526e-05,
      "loss": 0.9979,
      "step": 11500
    },
    {
      "epoch": 0.8250257820556892,
      "grad_norm": 2.3919403553009033,
      "learning_rate": 1.6699896871777244e-05,
      "loss": 1.0109,
      "step": 12000
    },
    {
      "epoch": 0.8594018563080096,
      "grad_norm": 2.845432758331299,
      "learning_rate": 1.6562392574767963e-05,
      "loss": 1.003,
      "step": 12500
    },
    {
      "epoch": 0.8937779305603301,
      "grad_norm": 4.736722469329834,
      "learning_rate": 1.642488827775868e-05,
      "loss": 0.9908,
      "step": 13000
    },
    {
      "epoch": 0.9281540048126504,
      "grad_norm": 2.89123272895813,
      "learning_rate": 1.62873839807494e-05,
      "loss": 1.0075,
      "step": 13500
    },
    {
      "epoch": 0.9625300790649708,
      "grad_norm": 2.229393482208252,
      "learning_rate": 1.6149879683740118e-05,
      "loss": 1.0051,
      "step": 14000
    },
    {
      "epoch": 0.9969061533172912,
      "grad_norm": 2.561732769012451,
      "learning_rate": 1.6012375386730837e-05,
      "loss": 0.9989,
      "step": 14500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.55022344448264,
      "eval_f1": 0.3905834864462097,
      "eval_loss": 1.0019532442092896,
      "eval_precision": 0.3027458388583409,
      "eval_recall": 0.55022344448264,
      "eval_runtime": 326.9979,
      "eval_samples_per_second": 88.961,
      "eval_steps_per_second": 11.122,
      "step": 14545
    },
    {
      "epoch": 1.0312822275696116,
      "grad_norm": 2.5150132179260254,
      "learning_rate": 1.5874871089721555e-05,
      "loss": 1.0103,
      "step": 15000
    },
    {
      "epoch": 1.0656583018219319,
      "grad_norm": 1.977171778678894,
      "learning_rate": 1.5737366792712274e-05,
      "loss": 1.0103,
      "step": 15500
    },
    {
      "epoch": 1.1000343760742524,
      "grad_norm": 1.0540319681167603,
      "learning_rate": 1.5599862495702992e-05,
      "loss": 1.0072,
      "step": 16000
    },
    {
      "epoch": 1.1344104503265726,
      "grad_norm": 2.1759467124938965,
      "learning_rate": 1.546235819869371e-05,
      "loss": 1.0094,
      "step": 16500
    },
    {
      "epoch": 1.168786524578893,
      "grad_norm": 1.2482205629348755,
      "learning_rate": 1.532485390168443e-05,
      "loss": 0.9985,
      "step": 17000
    },
    {
      "epoch": 1.2031625988312136,
      "grad_norm": 2.224579334259033,
      "learning_rate": 1.5187349604675147e-05,
      "loss": 1.0076,
      "step": 17500
    },
    {
      "epoch": 1.2375386730835338,
      "grad_norm": 2.141037702560425,
      "learning_rate": 1.5049845307665867e-05,
      "loss": 1.0037,
      "step": 18000
    },
    {
      "epoch": 1.2719147473358543,
      "grad_norm": 1.7932757139205933,
      "learning_rate": 1.4912341010656584e-05,
      "loss": 1.0061,
      "step": 18500
    },
    {
      "epoch": 1.3062908215881746,
      "grad_norm": 1.1960350275039673,
      "learning_rate": 1.4774836713647303e-05,
      "loss": 0.9837,
      "step": 19000
    },
    {
      "epoch": 1.340666895840495,
      "grad_norm": 3.6464715003967285,
      "learning_rate": 1.4637332416638021e-05,
      "loss": 1.0023,
      "step": 19500
    },
    {
      "epoch": 1.3750429700928155,
      "grad_norm": 2.791348695755005,
      "learning_rate": 1.4499828119628741e-05,
      "loss": 0.9953,
      "step": 20000
    },
    {
      "epoch": 1.4094190443451358,
      "grad_norm": 1.9346977472305298,
      "learning_rate": 1.4362323822619458e-05,
      "loss": 1.001,
      "step": 20500
    },
    {
      "epoch": 1.4437951185974562,
      "grad_norm": 2.12355375289917,
      "learning_rate": 1.4224819525610176e-05,
      "loss": 0.999,
      "step": 21000
    },
    {
      "epoch": 1.4781711928497765,
      "grad_norm": 2.0196268558502197,
      "learning_rate": 1.4087315228600895e-05,
      "loss": 0.9917,
      "step": 21500
    },
    {
      "epoch": 1.512547267102097,
      "grad_norm": 1.6567825078964233,
      "learning_rate": 1.3949810931591613e-05,
      "loss": 0.997,
      "step": 22000
    },
    {
      "epoch": 1.5469233413544172,
      "grad_norm": 2.385087013244629,
      "learning_rate": 1.381230663458233e-05,
      "loss": 0.9886,
      "step": 22500
    },
    {
      "epoch": 1.5812994156067377,
      "grad_norm": 2.0378661155700684,
      "learning_rate": 1.367480233757305e-05,
      "loss": 1.0106,
      "step": 23000
    },
    {
      "epoch": 1.6156754898590582,
      "grad_norm": 1.382384181022644,
      "learning_rate": 1.3537298040563769e-05,
      "loss": 1.0113,
      "step": 23500
    },
    {
      "epoch": 1.6500515641113784,
      "grad_norm": 1.5182695388793945,
      "learning_rate": 1.3399793743554487e-05,
      "loss": 0.9912,
      "step": 24000
    },
    {
      "epoch": 1.684427638363699,
      "grad_norm": 3.689331293106079,
      "learning_rate": 1.3262289446545204e-05,
      "loss": 1.015,
      "step": 24500
    },
    {
      "epoch": 1.7188037126160194,
      "grad_norm": 2.602614641189575,
      "learning_rate": 1.3124785149535924e-05,
      "loss": 0.998,
      "step": 25000
    },
    {
      "epoch": 1.7531797868683396,
      "grad_norm": 1.6764578819274902,
      "learning_rate": 1.2987280852526642e-05,
      "loss": 0.9972,
      "step": 25500
    },
    {
      "epoch": 1.78755586112066,
      "grad_norm": 1.8169513940811157,
      "learning_rate": 1.2849776555517361e-05,
      "loss": 1.0019,
      "step": 26000
    },
    {
      "epoch": 1.8219319353729804,
      "grad_norm": 3.132439374923706,
      "learning_rate": 1.2712272258508081e-05,
      "loss": 0.9987,
      "step": 26500
    },
    {
      "epoch": 1.8563080096253008,
      "grad_norm": 3.4432785511016846,
      "learning_rate": 1.2574767961498798e-05,
      "loss": 0.9992,
      "step": 27000
    },
    {
      "epoch": 1.890684083877621,
      "grad_norm": 2.102205753326416,
      "learning_rate": 1.2437263664489516e-05,
      "loss": 0.9924,
      "step": 27500
    },
    {
      "epoch": 1.9250601581299416,
      "grad_norm": 2.01786732673645,
      "learning_rate": 1.2299759367480235e-05,
      "loss": 1.0028,
      "step": 28000
    },
    {
      "epoch": 1.959436232382262,
      "grad_norm": 3.211374521255493,
      "learning_rate": 1.2162255070470955e-05,
      "loss": 1.0006,
      "step": 28500
    },
    {
      "epoch": 1.9938123066345823,
      "grad_norm": 2.487053394317627,
      "learning_rate": 1.2024750773461672e-05,
      "loss": 1.0024,
      "step": 29000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.55022344448264,
      "eval_f1": 0.3905834864462097,
      "eval_loss": 0.9990149736404419,
      "eval_precision": 0.3027458388583409,
      "eval_recall": 0.55022344448264,
      "eval_runtime": 327.4496,
      "eval_samples_per_second": 88.838,
      "eval_steps_per_second": 11.107,
      "step": 29090
    },
    {
      "epoch": 2.0281883808869026,
      "grad_norm": 4.20499324798584,
      "learning_rate": 1.188724647645239e-05,
      "loss": 1.0146,
      "step": 29500
    },
    {
      "epoch": 2.0625644551392233,
      "grad_norm": 2.003417730331421,
      "learning_rate": 1.1749742179443108e-05,
      "loss": 1.0116,
      "step": 30000
    },
    {
      "epoch": 2.0969405293915435,
      "grad_norm": 1.227920651435852,
      "learning_rate": 1.1612237882433827e-05,
      "loss": 1.0079,
      "step": 30500
    },
    {
      "epoch": 2.1313166036438638,
      "grad_norm": 1.4469051361083984,
      "learning_rate": 1.1474733585424544e-05,
      "loss": 0.9919,
      "step": 31000
    },
    {
      "epoch": 2.1656926778961845,
      "grad_norm": 3.0962424278259277,
      "learning_rate": 1.1337229288415264e-05,
      "loss": 1.0086,
      "step": 31500
    },
    {
      "epoch": 2.2000687521485047,
      "grad_norm": 1.7075973749160767,
      "learning_rate": 1.1199724991405982e-05,
      "loss": 1.0,
      "step": 32000
    },
    {
      "epoch": 2.234444826400825,
      "grad_norm": 2.514622211456299,
      "learning_rate": 1.10622206943967e-05,
      "loss": 1.0041,
      "step": 32500
    },
    {
      "epoch": 2.2688209006531452,
      "grad_norm": 1.2057548761367798,
      "learning_rate": 1.0924716397387417e-05,
      "loss": 0.9885,
      "step": 33000
    },
    {
      "epoch": 2.303196974905466,
      "grad_norm": 3.0491669178009033,
      "learning_rate": 1.0787212100378138e-05,
      "loss": 1.001,
      "step": 33500
    },
    {
      "epoch": 2.337573049157786,
      "grad_norm": 1.04495108127594,
      "learning_rate": 1.0649707803368856e-05,
      "loss": 1.0057,
      "step": 34000
    },
    {
      "epoch": 2.3719491234101064,
      "grad_norm": 3.749237060546875,
      "learning_rate": 1.0512203506359575e-05,
      "loss": 0.9956,
      "step": 34500
    },
    {
      "epoch": 2.406325197662427,
      "grad_norm": 3.117358684539795,
      "learning_rate": 1.0374699209350295e-05,
      "loss": 0.9981,
      "step": 35000
    },
    {
      "epoch": 2.4407012719147474,
      "grad_norm": 1.7843650579452515,
      "learning_rate": 1.0237194912341011e-05,
      "loss": 1.0012,
      "step": 35500
    },
    {
      "epoch": 2.4750773461670676,
      "grad_norm": 1.7707597017288208,
      "learning_rate": 1.009969061533173e-05,
      "loss": 0.9904,
      "step": 36000
    },
    {
      "epoch": 2.509453420419388,
      "grad_norm": 2.7504687309265137,
      "learning_rate": 9.962186318322448e-06,
      "loss": 0.9833,
      "step": 36500
    },
    {
      "epoch": 2.5438294946717086,
      "grad_norm": 2.1218886375427246,
      "learning_rate": 9.824682021313167e-06,
      "loss": 1.0056,
      "step": 37000
    },
    {
      "epoch": 2.578205568924029,
      "grad_norm": 0.9801654815673828,
      "learning_rate": 9.687177724303885e-06,
      "loss": 1.0006,
      "step": 37500
    },
    {
      "epoch": 2.612581643176349,
      "grad_norm": 1.6436899900436401,
      "learning_rate": 9.549673427294604e-06,
      "loss": 1.0036,
      "step": 38000
    },
    {
      "epoch": 2.64695771742867,
      "grad_norm": 1.0364649295806885,
      "learning_rate": 9.412169130285322e-06,
      "loss": 1.0047,
      "step": 38500
    },
    {
      "epoch": 2.68133379168099,
      "grad_norm": 2.65533185005188,
      "learning_rate": 9.27466483327604e-06,
      "loss": 1.0037,
      "step": 39000
    },
    {
      "epoch": 2.7157098659333103,
      "grad_norm": 3.5500969886779785,
      "learning_rate": 9.137160536266759e-06,
      "loss": 1.0029,
      "step": 39500
    },
    {
      "epoch": 2.750085940185631,
      "grad_norm": 1.2631573677062988,
      "learning_rate": 8.999656239257477e-06,
      "loss": 1.0084,
      "step": 40000
    },
    {
      "epoch": 2.7844620144379513,
      "grad_norm": 3.166940450668335,
      "learning_rate": 8.862151942248196e-06,
      "loss": 0.9943,
      "step": 40500
    },
    {
      "epoch": 2.8188380886902715,
      "grad_norm": 1.6480909585952759,
      "learning_rate": 8.724647645238914e-06,
      "loss": 0.996,
      "step": 41000
    },
    {
      "epoch": 2.8532141629425922,
      "grad_norm": 2.672126531600952,
      "learning_rate": 8.587143348229633e-06,
      "loss": 1.0007,
      "step": 41500
    },
    {
      "epoch": 2.8875902371949125,
      "grad_norm": 3.1181516647338867,
      "learning_rate": 8.449639051220351e-06,
      "loss": 1.0148,
      "step": 42000
    },
    {
      "epoch": 2.9219663114472327,
      "grad_norm": 3.27107310295105,
      "learning_rate": 8.31213475421107e-06,
      "loss": 0.985,
      "step": 42500
    },
    {
      "epoch": 2.956342385699553,
      "grad_norm": 1.0343176126480103,
      "learning_rate": 8.174630457201788e-06,
      "loss": 1.0038,
      "step": 43000
    },
    {
      "epoch": 2.9907184599518732,
      "grad_norm": 2.28434419631958,
      "learning_rate": 8.037126160192507e-06,
      "loss": 1.0023,
      "step": 43500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.55022344448264,
      "eval_f1": 0.3905834864462097,
      "eval_loss": 0.9990779757499695,
      "eval_precision": 0.3027458388583409,
      "eval_recall": 0.55022344448264,
      "eval_runtime": 326.7215,
      "eval_samples_per_second": 89.036,
      "eval_steps_per_second": 11.132,
      "step": 43635
    },
    {
      "epoch": 3.025094534204194,
      "grad_norm": 2.579909563064575,
      "learning_rate": 7.899621863183225e-06,
      "loss": 0.9932,
      "step": 44000
    },
    {
      "epoch": 3.059470608456514,
      "grad_norm": 2.989980697631836,
      "learning_rate": 7.762117566173943e-06,
      "loss": 1.0142,
      "step": 44500
    },
    {
      "epoch": 3.0938466827088345,
      "grad_norm": 2.4200656414031982,
      "learning_rate": 7.624613269164663e-06,
      "loss": 1.0082,
      "step": 45000
    },
    {
      "epoch": 3.128222756961155,
      "grad_norm": 2.759064197540283,
      "learning_rate": 7.48710897215538e-06,
      "loss": 1.0069,
      "step": 45500
    },
    {
      "epoch": 3.1625988312134754,
      "grad_norm": 3.7347311973571777,
      "learning_rate": 7.349604675146099e-06,
      "loss": 0.9992,
      "step": 46000
    },
    {
      "epoch": 3.1969749054657957,
      "grad_norm": 1.9173879623413086,
      "learning_rate": 7.212100378136817e-06,
      "loss": 0.9998,
      "step": 46500
    },
    {
      "epoch": 3.2313509797181164,
      "grad_norm": 3.6306421756744385,
      "learning_rate": 7.074596081127536e-06,
      "loss": 1.0043,
      "step": 47000
    },
    {
      "epoch": 3.2657270539704366,
      "grad_norm": 2.473874807357788,
      "learning_rate": 6.937091784118254e-06,
      "loss": 1.0056,
      "step": 47500
    },
    {
      "epoch": 3.300103128222757,
      "grad_norm": 2.4807510375976562,
      "learning_rate": 6.799587487108973e-06,
      "loss": 0.9942,
      "step": 48000
    },
    {
      "epoch": 3.3344792024750776,
      "grad_norm": 1.1349997520446777,
      "learning_rate": 6.662083190099691e-06,
      "loss": 0.9993,
      "step": 48500
    },
    {
      "epoch": 3.368855276727398,
      "grad_norm": 1.3655914068222046,
      "learning_rate": 6.5245788930904095e-06,
      "loss": 1.0048,
      "step": 49000
    },
    {
      "epoch": 3.403231350979718,
      "grad_norm": 1.2644603252410889,
      "learning_rate": 6.387074596081128e-06,
      "loss": 0.9897,
      "step": 49500
    },
    {
      "epoch": 3.4376074252320383,
      "grad_norm": 2.057852268218994,
      "learning_rate": 6.249570299071846e-06,
      "loss": 1.0045,
      "step": 50000
    },
    {
      "epoch": 3.471983499484359,
      "grad_norm": 1.4614542722702026,
      "learning_rate": 6.112066002062566e-06,
      "loss": 0.9874,
      "step": 50500
    },
    {
      "epoch": 3.5063595737366793,
      "grad_norm": 2.684690237045288,
      "learning_rate": 5.974561705053283e-06,
      "loss": 0.9999,
      "step": 51000
    },
    {
      "epoch": 3.5407356479889995,
      "grad_norm": 1.3916093111038208,
      "learning_rate": 5.837057408044003e-06,
      "loss": 0.9984,
      "step": 51500
    },
    {
      "epoch": 3.57511172224132,
      "grad_norm": 1.8841873407363892,
      "learning_rate": 5.69955311103472e-06,
      "loss": 0.9982,
      "step": 52000
    },
    {
      "epoch": 3.6094877964936405,
      "grad_norm": 3.8473033905029297,
      "learning_rate": 5.5620488140254395e-06,
      "loss": 0.9938,
      "step": 52500
    },
    {
      "epoch": 3.6438638707459607,
      "grad_norm": 2.1722452640533447,
      "learning_rate": 5.424544517016157e-06,
      "loss": 0.9975,
      "step": 53000
    },
    {
      "epoch": 3.678239944998281,
      "grad_norm": 1.2482962608337402,
      "learning_rate": 5.287040220006876e-06,
      "loss": 0.9949,
      "step": 53500
    },
    {
      "epoch": 3.7126160192506017,
      "grad_norm": 2.0942037105560303,
      "learning_rate": 5.149535922997594e-06,
      "loss": 0.9946,
      "step": 54000
    },
    {
      "epoch": 3.746992093502922,
      "grad_norm": 2.613645076751709,
      "learning_rate": 5.012031625988312e-06,
      "loss": 1.0112,
      "step": 54500
    },
    {
      "epoch": 3.781368167755242,
      "grad_norm": 4.114224433898926,
      "learning_rate": 4.874527328979031e-06,
      "loss": 0.9977,
      "step": 55000
    },
    {
      "epoch": 3.815744242007563,
      "grad_norm": 2.2303240299224854,
      "learning_rate": 4.737023031969749e-06,
      "loss": 0.9966,
      "step": 55500
    },
    {
      "epoch": 3.850120316259883,
      "grad_norm": 1.0282655954360962,
      "learning_rate": 4.599518734960468e-06,
      "loss": 1.0054,
      "step": 56000
    },
    {
      "epoch": 3.8844963905122034,
      "grad_norm": 1.0374772548675537,
      "learning_rate": 4.462014437951186e-06,
      "loss": 1.0079,
      "step": 56500
    },
    {
      "epoch": 3.918872464764524,
      "grad_norm": 1.8034090995788574,
      "learning_rate": 4.324510140941905e-06,
      "loss": 1.0054,
      "step": 57000
    },
    {
      "epoch": 3.9532485390168444,
      "grad_norm": 4.6572265625,
      "learning_rate": 4.187005843932623e-06,
      "loss": 0.9968,
      "step": 57500
    },
    {
      "epoch": 3.9876246132691646,
      "grad_norm": 1.370072841644287,
      "learning_rate": 4.0495015469233416e-06,
      "loss": 1.0074,
      "step": 58000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.55022344448264,
      "eval_f1": 0.3905834864462097,
      "eval_loss": 0.9997726678848267,
      "eval_precision": 0.3027458388583409,
      "eval_recall": 0.55022344448264,
      "eval_runtime": 326.239,
      "eval_samples_per_second": 89.168,
      "eval_steps_per_second": 11.148,
      "step": 58180
    },
    {
      "epoch": 4.022000687521485,
      "grad_norm": 1.3911676406860352,
      "learning_rate": 3.91199724991406e-06,
      "loss": 0.9989,
      "step": 58500
    },
    {
      "epoch": 4.056376761773805,
      "grad_norm": 2.2608580589294434,
      "learning_rate": 3.7744929529047784e-06,
      "loss": 0.9969,
      "step": 59000
    },
    {
      "epoch": 4.090752836026126,
      "grad_norm": 1.2436981201171875,
      "learning_rate": 3.636988655895497e-06,
      "loss": 0.9993,
      "step": 59500
    },
    {
      "epoch": 4.1251289102784465,
      "grad_norm": 7.739761829376221,
      "learning_rate": 3.4994843588862153e-06,
      "loss": 1.0001,
      "step": 60000
    },
    {
      "epoch": 4.159504984530766,
      "grad_norm": 2.901503801345825,
      "learning_rate": 3.361980061876934e-06,
      "loss": 0.9982,
      "step": 60500
    },
    {
      "epoch": 4.193881058783087,
      "grad_norm": 3.158303737640381,
      "learning_rate": 3.2244757648676522e-06,
      "loss": 0.9968,
      "step": 61000
    },
    {
      "epoch": 4.228257133035408,
      "grad_norm": 1.2226768732070923,
      "learning_rate": 3.0869714678583707e-06,
      "loss": 0.9934,
      "step": 61500
    },
    {
      "epoch": 4.2626332072877275,
      "grad_norm": 1.5811195373535156,
      "learning_rate": 2.949467170849089e-06,
      "loss": 0.9995,
      "step": 62000
    },
    {
      "epoch": 4.297009281540048,
      "grad_norm": 2.956543207168579,
      "learning_rate": 2.8119628738398076e-06,
      "loss": 0.9938,
      "step": 62500
    },
    {
      "epoch": 4.331385355792369,
      "grad_norm": 2.918006658554077,
      "learning_rate": 2.674458576830526e-06,
      "loss": 0.9988,
      "step": 63000
    },
    {
      "epoch": 4.365761430044689,
      "grad_norm": 1.4017587900161743,
      "learning_rate": 2.536954279821245e-06,
      "loss": 0.9953,
      "step": 63500
    },
    {
      "epoch": 4.4001375042970094,
      "grad_norm": 2.807110548019409,
      "learning_rate": 2.399449982811963e-06,
      "loss": 1.0047,
      "step": 64000
    },
    {
      "epoch": 4.434513578549329,
      "grad_norm": 2.0252082347869873,
      "learning_rate": 2.2619456858026814e-06,
      "loss": 1.0056,
      "step": 64500
    },
    {
      "epoch": 4.46888965280165,
      "grad_norm": 1.293604850769043,
      "learning_rate": 2.1244413887934e-06,
      "loss": 1.0092,
      "step": 65000
    },
    {
      "epoch": 4.503265727053971,
      "grad_norm": 2.1161069869995117,
      "learning_rate": 1.9869370917841187e-06,
      "loss": 0.996,
      "step": 65500
    },
    {
      "epoch": 4.5376418013062905,
      "grad_norm": 2.241499423980713,
      "learning_rate": 1.849432794774837e-06,
      "loss": 0.9907,
      "step": 66000
    },
    {
      "epoch": 4.572017875558611,
      "grad_norm": 3.3938634395599365,
      "learning_rate": 1.7119284977655554e-06,
      "loss": 1.0144,
      "step": 66500
    },
    {
      "epoch": 4.606393949810932,
      "grad_norm": 1.0059329271316528,
      "learning_rate": 1.5744242007562738e-06,
      "loss": 1.0024,
      "step": 67000
    },
    {
      "epoch": 4.640770024063252,
      "grad_norm": 3.1246249675750732,
      "learning_rate": 1.4369199037469923e-06,
      "loss": 0.9954,
      "step": 67500
    },
    {
      "epoch": 4.675146098315572,
      "grad_norm": 5.244500637054443,
      "learning_rate": 1.2994156067377107e-06,
      "loss": 0.9991,
      "step": 68000
    },
    {
      "epoch": 4.709522172567893,
      "grad_norm": 2.932499885559082,
      "learning_rate": 1.1619113097284292e-06,
      "loss": 0.9966,
      "step": 68500
    },
    {
      "epoch": 4.743898246820213,
      "grad_norm": 1.5022532939910889,
      "learning_rate": 1.0244070127191476e-06,
      "loss": 1.0033,
      "step": 69000
    },
    {
      "epoch": 4.778274321072534,
      "grad_norm": 1.1765620708465576,
      "learning_rate": 8.86902715709866e-07,
      "loss": 0.989,
      "step": 69500
    },
    {
      "epoch": 4.812650395324854,
      "grad_norm": 3.238314390182495,
      "learning_rate": 7.493984187005844e-07,
      "loss": 1.0039,
      "step": 70000
    },
    {
      "epoch": 4.847026469577174,
      "grad_norm": 4.144308567047119,
      "learning_rate": 6.118941216913028e-07,
      "loss": 0.9981,
      "step": 70500
    },
    {
      "epoch": 4.881402543829495,
      "grad_norm": 2.845672369003296,
      "learning_rate": 4.743898246820214e-07,
      "loss": 1.0005,
      "step": 71000
    },
    {
      "epoch": 4.915778618081815,
      "grad_norm": 4.36604642868042,
      "learning_rate": 3.368855276727398e-07,
      "loss": 1.013,
      "step": 71500
    },
    {
      "epoch": 4.950154692334135,
      "grad_norm": 2.71899151802063,
      "learning_rate": 1.9938123066345824e-07,
      "loss": 1.005,
      "step": 72000
    },
    {
      "epoch": 4.984530766586456,
      "grad_norm": 1.3998459577560425,
      "learning_rate": 6.18769336541767e-08,
      "loss": 1.0067,
      "step": 72500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.55022344448264,
      "eval_f1": 0.3905834864462097,
      "eval_loss": 0.999069094657898,
      "eval_precision": 0.3027458388583409,
      "eval_recall": 0.55022344448264,
      "eval_runtime": 325.7578,
      "eval_samples_per_second": 89.299,
      "eval_steps_per_second": 11.165,
      "step": 72725
    }
  ],
  "logging_steps": 500,
  "max_steps": 72725,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.826951771676544e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
